<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> node爬虫 · indexOf的博客</title><meta name="description" content="node爬虫 - Flyover"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://indexof.site/atom.xml" title="indexOf的博客"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="http://weibo.com/sunchongsheng" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://github.com/pinggod" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">node爬虫</h1><div class="post-info">Jul 25, 2016</div><div class="post-content"><blockquote>
<p>其实node写爬虫并不是特别合适，主要的原因，就是库的支持程度没有python那么高了。当然本着学习node的态度还是可以的。网上教用node写爬虫的一大堆，我这里不具体讲，怎么爬。就写写大体上的思路和可能会遇到的一些问题。</p>
</blockquote>
<p>首先先给出几个node写爬虫的几个简单教程   </p>
<ol>
<li><a href="https://github.com/alsotang/node-lessons/tree/master/lesson3" target="_blank" rel="external">使用 superagent 与 cheerio 完成简单爬虫</a>     </li>
<li><a href="http://www.cnblogs.com/hustskyking/p/spider-with-node.html" target="_blank" rel="external">NodeJS写个爬虫，把文章放到kindle中阅读</a>   </li>
<li><a href="http://blog.didispace.com/nodejspachong/" target="_blank" rel="external">使用Node.js制作爬虫教程</a><a id="more"></a>
</li>
</ol>
<p>想用node写爬虫的小白同学可以照着学一下。<br>然后我这边就主要讲一下爬虫思路。<br>所谓爬虫无非是要别人的网站页面上，获取到有价值的信息并保存下来。<br>那么流程上就成了：<img src="//blog-indexof.oss-cn-shanghai.aliyuncs.com/node爬虫.md/0.png" alt=""><br>一个环节一个环节简单说下。除了数据分析，因为我不会。。。。  </p>
<ol>
<li>获取html就是用node发请求取获取指定网站上的html源码。在这个步骤上，还是有蛮多库可以选择的。当然也可用原生node的http库做这个事。 其他三方库也是蛮多的，比如：<a href="https://github.com/request/request" target="_blank" rel="external">request</a>, <a href="https://github.com/visionmedia/superagent" target="_blank" rel="external">superagent</a>,etc。<br><strong><em>这里需要注意的事</em></strong>， 当请求一下子发太多，因为网络问题，会导致大量请求失败。所以这里最好引入一个三方库（<a href="https://github.com/tj/co" target="_blank" rel="external">co</a>, <a href="https://github.com/caolan/async" target="_blank" rel="external">async</a>），来控制请求数。保证一下子请求不要太多。</li>
<li>分析html。简单的可以直接用正则表达式，复杂的可以用<a href="https://github.com/cheeriojs/cheerio" target="_blank" rel="external">cheerio</a>，这个库基本上就是node端的jquery。所以用jq获取页面的对应信息还是比较简单的。<br><strong><em>当然也有坑</em></strong>, 当直接能获取到html源码的网页，用这种方式当然可以了。但是想新浪微博之类的把html写在js代码里，需要运行js才能渲染出页面的网站。就是自己稍稍动动脑筋，用<code>eval</code>执行下js，还是能渲染页面的。但是如果遇到spa框架写的页面。那基本上就没戏了。<br>需要换方案解决，可以用<a href="http://phantomjs.org/" target="_blank" rel="external">phantomjs</a>之类的无头浏览器。正常访问页面，然后正常获取数据的方式来做。     </li>
<li>保存数据基本上很简单了。自己玩玩的项目可以直接用fs写文件。大项目需要做数据分析的就放入数据库。</li>
<li>分析大量数据。不会。。。。。。</li>
</ol>
<blockquote>
<p>以上就是我对node爬虫的一些认识。</p>
</blockquote>
</div></article></div></main><footer><div class="paginator"><a href="/20160727/shadowsock/" class="prev">PREV</a><a href="/20160717/httpProxy/" class="next">NEXT</a></div><div class="copyright"><p>© 2015 - 2018 <a href="http://indexof.site">Flyover</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>